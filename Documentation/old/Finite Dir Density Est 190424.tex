
\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bm}
\usepackage{upgreek}

%\usepackage[retainorgcmds]{IEEEtrantools}

\usepackage[nottoc]{tocbibind}


\linespread{1.3}


\title{Predictive Distribution Estimation for Bayesian Machine Learning using a Dirichlet Prior}

%\author{Paul Rademacher}
\author{\IEEEauthorblockN{Paul Rademacher}
\IEEEauthorblockA{Naval Research Laboratory}}


%\graphicspath{ {C:/Users/Paul/Documents/PhD/Dissertation/Documentation/Figures/} }
\graphicspath{ {../Figures/} }


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\DeclareMathOperator{\xrm}{\mathrm{x}}
\DeclareMathOperator{\Xrm}{\mathrm{X}}
\DeclareMathOperator{\yrm}{\mathrm{y}}
\DeclareMathOperator{\Yrm}{\mathrm{Y}}
\DeclareMathOperator{\Drm}{\mathrm{D}}
\DeclareMathOperator{\nrm}{\mathrm{n}}
\DeclareMathOperator{\nbarrm}{\bar{\mathrm{n}}}
\DeclareMathOperator{\zrm}{\mathrm{z}}

\DeclareMathOperator{\Prm}{\mathrm{P}}
\DeclareMathOperator{\prm}{\mathrm{p}}
\DeclareMathOperator{\Erm}{\mathrm{E}}
\DeclareMathOperator{\Crm}{\mathrm{C}}

\DeclareMathOperator{\Xcal}{\mathcal{X}}
\DeclareMathOperator{\Ycal}{\mathcal{Y}}
\DeclareMathOperator{\Dcal}{\mathcal{D}}
\DeclareMathOperator{\Ncal}{\mathcal{N}}
\DeclareMathOperator{\Zcal}{\mathcal{Z}}
\DeclareMathOperator{\Hcal}{\mathcal{H}}
\DeclareMathOperator{\Fcal}{\mathcal{F}}
\DeclareMathOperator{\Rcal}{\mathcal{R}}
\DeclareMathOperator{\Mcal}{\mathcal{M}}
\DeclareMathOperator{\Scal}{\mathcal{S}}
\DeclareMathOperator{\Pcal}{\mathcal{P}}

\DeclareMathOperator{\Rbb}{\mathbb{R}}
\DeclareMathOperator{\Nbb}{\mathbb{N}}
\DeclareMathOperator{\Zbb}{\mathbb{Z}}

\DeclareMathOperator{\Dir}{\mathrm{Dir}}
\DeclareMathOperator{\DM}{\mathrm{DM}}
\DeclareMathOperator{\Mult}{\mathrm{Mult}}
\DeclareMathOperator{\DP}{\mathrm{DP}}









\begin{document}

\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
In Bayesian treatments of machine learning, the success or failure of the estimator/classifier hinges on how well the prior distribution selected by the designer matches the actual data-generating model. This paper assumes a Dirichlet prior over a finite set and assesses the mismatch between the true predictive distribution and the distribution approximated using the training data. It is shown that highly subjective Dirichlet priors can overcome the burden of a limited training set when well matched to the true distribution, but will degrade the approximation if the prior estimate is poor. A bias/variance tradeoff will be demonstrated with illustrative examples.
\end{abstract}


\section{Background}

This report details a Bayesian perspective on stastical learning theory when both the observations and unobserved quantities exist in finite dimensional spaces. While the validity of Bayesian methods for statistical signal processing and machine learning has long been contended, the author believes it to be a justified approach that does not necessarily imply that the distribution model is `random'; rather, it simply reflects the desire of the user to formulate risk as a weighted sum of learner performance across the space of distributions. 

The success or failure of Bayesian learning methods hinge on how well the prior knowledge imparted by the designer matches reality. The chosen prior distribution over the set of data-generating probability mass functions (PMF) reflects the users confidence that different PMF's are responsible for generating the observed/unobserved random elements. If a highly subjective prior is chosen that strongly weights the actual data PMF, low risk learning functions are possible even with limited training data; however, if the prior is poorly selected, a good solution will never be achieved. Conversely, an objective prior that treats the different PMF's equally will always be able to adapt will enough training data; if data is limited, however, the learning function may not deliver the required performance.

This work assumes that the prior distribution is Dirichlet. The class of Dirichlet probability density functions (PDF) have the desirable properties of full support over the set of possible PMF's and a tractable posterior distribution for independently and identically distributed data \cite{ferguson}. Furthermore, control of the Dirichlet parameters can enable both objective and subjective prior knowledge.

After introducing the problem and discussing the relevant data probability distributions, the Bayesian framework will be applied to the regression problem using the squared-error loss function. Optimal estimators and the corresponding minimum risk will be presented for different prior distributions. Specific attention will be given to various asymptotic cases to show the differing performance for objective and subjective Dirichlet priors.







\section{Objective}

Consider an observable discrete random element $\xrm \in \Xcal$ and and unobservable discrete random element $\yrm \in \Ycal$ which are jointly distributed according to an unknown PMF $\uptheta \in \Theta = \Pcal(\Ycal \times \Xcal)$, such that $\Prm_{\yrm,\xrm | \uptheta}(y,x) = \uptheta(y,x)$. Also observed is a random sequence of $N$ samples from $\uptheta$, denoted $\Drm = ( \Yrm,\Xrm ) \in \Dcal = \{\Ycal \times \Xcal\}^N$. The $N$ data pairs are conditionally independent from one another and are identically distributed as $\Prm_{\Drm_n | \theta}(y,x) = \uptheta(y,x)$. The samples are also conditionally independent from $(\yrm,\xrm)$. Thus,
\begin{equation}
\Prm(\yrm,\xrm,\Drm | \theta) = \Prm(\yrm,\xrm | \uptheta) \prod_{n=1}^N \Prm\big( \Drm_n | \theta \big) \;.
\end{equation}

The objective is to design a decision function $f: \Dcal \mapsto \Hcal^{\Xcal}$ which produces a mapping from the space of the observed random elements to a decision space $\Hcal$. Define the function space $\Fcal = \left\{ {\Hcal^{\Xcal}} \right\}^{\Dcal}$, such that $f \in \Fcal$. 

The metric guiding the design is a loss function $\mathcal{L}: \Hcal \times \Ycal \mapsto \Rbb_{\geq 0}$ which penalizes the decision $h \in \Hcal$ based on the value of $\yrm$. Introduce the conditional expected loss, or conditional ``risk'',
\begin{equation} \label{eq:risk_cond}
\Rcal_{\Theta}(f ; \uptheta) = \Erm_{\Drm | \uptheta} \bigg[ \Erm_{\yrm,\xrm | \uptheta} \Big[ \mathcal{L}\big( f(\xrm;\Drm),\yrm \big) \Big] \bigg] \;.
\end{equation}



If the model $\uptheta$ were known and the decision function domain extended to $\Dcal \times \Theta$, a ``clairvoyant'' function $f_{\Theta}$ could be found to minimize this objective. For a given set of observations, this function selects the decision $h = \argmin_{h \in \Hcal} \Erm_{\yrm | \xrm,\Drm,\uptheta}\big[ \mathcal{L}(h,\yrm) \big]$. It can be shown that given the model $\uptheta$, the unobserved element $\yrm$ is conditionally independent of the training data $\Drm$. As such, the knowledge of $\uptheta$ renders $\Drm$ uninformative and the clairvoyant decision function is recast as $f_{\Theta} : \Theta \to \Hcal^{\Xcal}$, expressed by
\begin{equation}
f_{\Theta}(\xrm;\uptheta) = \argmin_{h \in \Hcal} \Erm_{\yrm | \xrm,\uptheta}\big[ \mathcal{L}(h,\yrm) \big] \;.
\end{equation}
The corresponding irreducible risk is
\begin{equation} \label{eq_risk_min}
\Rcal_{\Theta}(f_{\Theta} ; \uptheta) = \Erm_{\xrm | \uptheta} \left[ \min_{h \in \Hcal} \Erm_{\yrm | \xrm,\uptheta}\big[ \mathcal{L}(h,\yrm) \big] \right] \;.
\end{equation}



However, as the model $\theta$ is not observed, $\Rcal_{\Theta}: \Theta \mapsto {\Rbb_{\geq 0}}^{\Fcal}$ is not yet a valid objective function for optimization. An operator must be chosen to remove the dependency on $\theta$ and form an objective function $\Fcal \mapsto \Rbb_{\geq 0}$.

One choice is to integrate over $\Theta$; to ensure a non-negative objective value, the weighting function should be non-negative. Also, as scaling the objective function will not change its minimizing argument, the weighting function can be constrained to integrate to one. These are the requirements for a valid probability density function (PDF); as such, the model $\uptheta$ is treated as a random process and a Bayesian approach can be adopted. 

Define the PDF $\prm(\uptheta): \Theta \mapsto \Rbb_{\geq 0}$. Now the Bayes risk can be formulated as
\begin{IEEEeqnarray}{rCl} \label{eq:risk}
\Rcal(f) & = & \Erm_{\uptheta}\big[ \Rcal_{\Theta}(f ; \uptheta) \big] \\
& = & \Erm_{\yrm,\xrm,\Drm}\big[ \mathcal{L}(f(\xrm;\Drm),\yrm) \big] \nonumber \\
& = & \Erm_{\xrm,\Drm}\Big[ \Erm_{\yrm | \xrm,\Drm} \big[ \mathcal{L}(f(\xrm;\Drm),\yrm) \big] \Big] \nonumber
\end{IEEEeqnarray}
and $\yrm$, $\xrm$, and $\Drm$ are jointly distributed random elements.

Finally, express the optimal learning function
\begin{equation} 
f^* = \argmin_{f \in \Fcal} \Rcal(f) \;.
\end{equation}
The learning functions are non-parametric and there are no restrictions on the set of achievable functions $\Fcal$. Thus, to minimize the risk, the decision expressed by the learning function $f$ for each observed value $\xrm$ and $\Drm$ is determined to be
\begin{equation} \label{eq:f_opt_xD}
f^*(\xrm;\Drm) = \argmin_{h \in \Hcal} \Erm_{\yrm | \xrm,\Drm}\big[ \mathcal{L}(h,\yrm) \big] \;.
\end{equation}
The optimal function achieves the minimum risk,
\begin{equation} \label{eq_risk_min}
\Rcal(f^*) = \Erm_{\xrm,\Drm} \left[ \min_{h \in \Hcal} \Erm_{\yrm | \xrm,\Drm}\big[ \mathcal{L}(h,\yrm) \big] \right] \;.
\end{equation}

















\section{Probability Distributions}

To determine the optimal decision function, the joint PMF $\Prm(\yrm,\xrm,\Drm)$ is required. Having already defined the distribution conditioned on the model $\uptheta$, all that remains is to select a PDF $\prm(\uptheta)$ reflecting the users prior knowledge. In this section, the Dirichlet distribution is used. The Dirichlet distribution possesses the desirable property of being the conjugate prior for the multinomial conditional distribution characterizing the data; as such, it will provide tractable forms for the model posterior distribution and lead to closed form expressions for the data conditional distribution used to design the decision function.

Other distributions of interest will be provided, such as the training data PMF $\Prm(\Drm)$ and the conditional distribution $\Prm(\yrm | \xrm,\Drm)$ used to form a decision given specific observations.



\subsection{Model PDF, $\prm(\uptheta)$} \label{sec:P_theta}

The Dirichlet PDF for the model $\uptheta \in \Theta$ is \cite{bishop}
\begin{IEEEeqnarray}{rCl}
\prm(\uptheta) & = & \beta(\alpha)^{-1} \prod_{y \in \Ycal} \prod_{x \in \Xcal} \uptheta(y,x)^{\alpha(y,x) - 1} \;,
\end{IEEEeqnarray}
where the user-selected PDF parameters $\alpha : \Ycal \times \Xcal \mapsto \Rbb^+$ are introduced and $\beta$ is the generalized beta function.

The parameter $\alpha$ controls around which models $\uptheta$ the PDF concentrates and how strongly. For convenience, introduce the concentration parameter $\alpha_0 \equiv \sum_{y \in \Ycal} \sum_{x \in \Xcal} \alpha(y,x)$. 

The mean and covariance functions of the model are 
\begin{equation}
\mu_{\uptheta}(y,x) = \Erm\big[ \uptheta(y,x) \big] = \frac{\alpha(y,x)}{\alpha_0}
\end{equation}
and
\begin{IEEEeqnarray}{rCl}
\Sigma_{\uptheta}(y,x,y',x') & = & \Erm\Big[ \big(\uptheta(y,x)-\mu_{\uptheta}(y,x)\big) \big(\uptheta(y',x')-\mu_{\uptheta}(y',x')\big) \Big] \\
& = & \frac{\mu_{\uptheta}(y,x) \delta[y,y'] \delta[x,x'] - \mu_{\uptheta}(y,x) \mu_{\uptheta}(y',x')}{\alpha_0+1} \nonumber \;.
\end{IEEEeqnarray}
Observe that $\Prm(\yrm,\xrm) = \mu_{\uptheta}(\yrm,\xrm) = \alpha(\yrm,\xrm) / \alpha_0$.

Of specific interest is how $\prm(\uptheta)$ changes as the concentration parameter approaches its limiting values. For $\alpha_0 \to \infty$, the PDF concentrates at its mean, resulting in
\begin{IEEEeqnarray}{rCl}
\prm(\uptheta) & = & \delta\left( \uptheta - \frac{\alpha}{\alpha_0} \right) \;.
\end{IEEEeqnarray}
Conversely, for $\alpha_0 \to 0$, the PDF trends toward
\begin{IEEEeqnarray}{rCl}
\prm(\uptheta) & = & \sum_{y \in \Ycal} \sum_{x \in \Xcal} \frac{\alpha(y,x)}{\alpha_0} \delta\big( \uptheta - \delta[\cdot,y] \delta[\cdot,x] \big) \;,
\end{IEEEeqnarray}
which distributes its weight among the $|\Ycal| |\Xcal|$ models with an $\ell_0$ norm satisfying $\| \theta \|_0 = 1$. Note that the Dirac delta for these formulas is defined on the set $\Theta$, such that $\int_{\Theta} \delta(\theta) \mathrm{d}\theta = 1$.

These trends are demonstrated with Figure \ref{fig:P_theta}. The cardinalities $|\Ycal| = 3$ and $|\Xcal| = 1$ are chosen to enable visualization, despite the implication that $\xrm$ is deterministic; these cardinalities will be used for many subsequent figures as well. Note that for $\alpha_0=2.99$, $\alpha < 1$ and the PDF values at the boundaries of the domain trend to infinity; this is not captured by the plot color scale.

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{P_theta.pdf}
\caption{Model prior PDF $\prm(\uptheta)$ for different concentrations $\alpha_0$}
\label{fig:P_theta}
\end{figure}





\subsubsection{Aggregation Properties}

As $\xrm$ is observable and $\yrm$ is not, the marginal distribution $\uptheta'$ over the set $\Xcal$, defined as $\uptheta'(x) \equiv \sum_{y \in \Ycal} \uptheta(y,x)$, will also be of interest. By the aggregation property \cite{ferguson}, $\uptheta'$ is a Dirichlet random process parameterized by $\alpha'$, where $\alpha'(x) \equiv \sum_{y \in \Ycal} \alpha(y,x)$. Note that $\Prm(\xrm) = \alpha'(\xrm) / \alpha_0$, $\Prm(\yrm|\xrm) = \alpha(\yrm,\xrm) / \alpha'(\xrm)$, and $\Prm(\yrm | \xrm,\uptheta) = \uptheta(\yrm,\xrm)/\uptheta'(\xrm)$. 

Also of interest is the joint distribution of the normalized functions $\tilde{\uptheta}(\cdot;x) \equiv \uptheta(\cdot,x) / \uptheta'(x)$ conditioned on the aggregation $\uptheta'$. It can be shown that the conditional PDF is
\begin{IEEEeqnarray}{rCl}
\prm\big( \tilde{\uptheta} | \uptheta' \big) & = & \prod_{x \in \Xcal} \Bigg[ \beta\big( \alpha(\cdot,x) \big)^{-1} \prod_{y \in \Ycal} \tilde{\uptheta}(y;x)^{\alpha(y,x)-1} \Bigg] \\
& = & \prod_{x \in \Xcal} \Dir\Big( \tilde{\uptheta}(\cdot,x) ; \alpha(\cdot,x) \Big) \nonumber \;,
\end{IEEEeqnarray}
a product of Dirichlet distributions defined for $\tilde{\theta} \in \left\{ \tilde{\theta}(\cdot,x) \in \Pcal(\Ycal), \quad \forall x \in \Xcal \right\}$. As shown, the normalized functions $\tilde{\uptheta}(\cdot;x)$ are independent of one another and of the aggregation $\uptheta'$.








\subsection{Training Set conditional PMF, $\Prm(\Drm | \uptheta)$}

Next, properties of the conditional distribution $\Prm(\Drm | \uptheta)$ will be discussed. The distribution of $\Drm$ conditioned on the model can be formulated as
\begin{IEEEeqnarray}{rCl}
\Prm\big( \Drm | \uptheta \big) & = & \prod_{n=1}^N \Prm\big( \Drm_n | \theta \big) \\
& = & \prod_{y \in \Ycal} \prod_{x \in \Xcal} \uptheta(y,x)^{\bar{N}(y,x;\Drm)} \nonumber \;,
\end{IEEEeqnarray}
where the dependency on the training data $\Drm$ is expressed though a transform function $\bar{N} : \Dcal \mapsto \bar{\Ncal}$, defined as
\begin{IEEEeqnarray}{rCl}
\bar{N}(y,x;D) & = & \sum_{n=1}^N \delta \big[ (y,x),D_n \big] \\
& = & \sum_{n=1}^N \delta \left[ y,Y_n \right] \delta \left[ x,X_n \right] \nonumber \;,
\end{IEEEeqnarray}
which counts the number of occurences of the pair $(y,x)$ in the training set $D$. The range of the transform is the function space 
\begin{IEEEeqnarray}{rCl}
\bar{\Ncal} & = & \left\{ \bar{n} \in {\Zbb_{\geq 0}}^{\Ycal \times \Xcal}: \sum_{y \in \Ycal} \sum_{x \in \Xcal} \bar{n}(y,x) = N \right\} \;.
\end{IEEEeqnarray}

Note that $\Prm(\Drm | \uptheta)$ depends on the training data $\Drm$ only through the transform $\bar{N}$; consequently, $\bar{N}(\Drm)$ will be a sufficient statistic for any distributions conditioned on $\Drm$. As such, it is useful to define a new random process $\nbarrm \equiv \bar{N}(\Drm) \in \bar{\Ncal}$. 

The cardinality of the random process' domain is $|\bar{\Ncal}| = \Mcal\big( \{N,|\Ycal||\Xcal|-1\} \big)$; this can be shown using the stars-and-bars method \cite{feller}. The cardinality of original set is $|\Dcal| = \big( |\Ycal| |\Xcal| \big)^N$; thus $|\bar{\Ncal}| \leq |\Dcal|$ and the sufficient statistic compactly represents the valuable information in the training data. 

Conditioned on the model $\uptheta$, the PMF of $\nbarrm$ is a multinomial distribution
\begin{IEEEeqnarray}{rCl}
\Prm(\nbarrm | \uptheta) & = & \sum_{D : \bar{N}(D) = \nbarrm} \Prm_{\Drm | \uptheta}(D | \uptheta) \\
& = & \big|\{ D : \bar{N}(D) = \nbarrm \}\big| \prod_{y \in \Ycal} \prod_{x \in \Xcal} \uptheta(y,x)^{\bar{\nrm}(y,x)} \nonumber \\
& = & \Mcal(\nbarrm) \prod_{y \in \Ycal} \prod_{x \in \Xcal} \uptheta(y,x)^{\bar{\nrm}(y,x)} \nonumber \;,
\end{IEEEeqnarray}
where the multinomial operator $\Mcal$ is used. The mean and covariance functions of this multinomial distribution are \cite{theodoridis-ML}
\begin{IEEEeqnarray}{rCl}
\mu_{\bar{\nrm} | \uptheta}(y,x) & = & \Erm_{\bar{\nrm} | \uptheta}\big[ \bar{\nrm}(y,x) \big] = N \uptheta(y,x)
\end{IEEEeqnarray}
and
\begin{IEEEeqnarray}{rCl}
\Sigma_{\nbarrm | \uptheta}(y,x,y',x')  & = & N \big( \uptheta(y,x) \delta[y,y'] \delta[x,x'] - \uptheta(y,x) \uptheta(y',x') \big) \;.
\end{IEEEeqnarray}







\subsubsection{Aggregation Properties}

As performed for the model $\uptheta$, a characterization of the function $\nbarrm$ integrated over the set $\Ycal$ will be found. Introduce the function $N' : \Dcal \to \Ncal'$, defined as
\begin{IEEEeqnarray}{rCl}
N'(x;D) & = & \sum_{y \in \Ycal} \bar{N}(y,x;D) = \sum_{n=1}^N \delta\big[ x,X_n \big]
\end{IEEEeqnarray}
where 
\begin{IEEEeqnarray}{rCl}
\Ncal' & = & \left\{ n' \in {\Zbb_{\geq 0}}^{\Xcal}: \sum_{x \in \Xcal} n'(x) = N \right\} \;.
\end{IEEEeqnarray}
Define the ``marginalized'' random process $\nrm'$ over the set $\Xcal$, defined as $\nrm'(x) \equiv \sum_{y \in \Ycal} \nbarrm(y,x) \equiv N'(\Drm)$. 


By the aggregation property of Multinomial random processes \cite{johnson}, the aggregation conditioned on the model $\uptheta$ is distributed as $\nrm' | \uptheta \sim \Mult(N,\uptheta')$. 

Also of interest is the distribution of $\nbarrm$ conditioned on its aggregation $\nrm'$. It can be shown that when conditioned on the model $\uptheta$ as well, the PMF for $\nbarrm$ is
\begin{IEEEeqnarray}{rCl}
\Prm(\bar{\nrm} | \nrm' , \uptheta) & = & \prod_{x \in \Xcal} \Bigg[ \Mcal\big( \bar{\nrm}(\cdot,x) \big) \prod_{y \in \Ycal} \left(\frac{\uptheta(y,x)}{\uptheta'(x)}\right)^{\bar{\nrm}(y,x)} \Bigg] \\
& = & \prod_{x \in \Xcal} \Mult\Big( \bar{\nrm}(\cdot,x) ; \nrm'(x) , \uptheta(\cdot,x) / \uptheta'(x) \Big) \nonumber \;,
\end{IEEEeqnarray}
which has support $\bar{\nrm} \in \left\{ {\Zbb_{\geq 0}}^{\Ycal \times \Xcal} : \sum_{y \in \Ycal} \bar{n}(y,x) = \nrm'(x), \quad \forall x \in \Xcal \right\}$. Observe that conditioning on the aggregation renders the function segments $\nbarrm(\cdot,x)$ independent of one another and that they are also Multinomial, such that $\nbarrm(\cdot,x) | \nrm'(x),\uptheta \sim \Mult\big( \nrm'(x),\uptheta(\cdot,x) / \uptheta'(x) \big)$.









\subsection{Observation Conditonal PMF, $\Prm(\yrm | \xrm,\Drm)$}

As shown in Equation \eqref{eq:f_opt_xD}, the decision selected by the optimally designed function depends on $\Prm(\yrm | \xrm,\Drm)$, the distribution of the unobserved $\yrm$ conditioned on all observable random elements. This PMF will be expressed next.

First observe that since $\Prm(\Drm | \uptheta)$ is of exponential form, the Dirichlet prior $\prm(\uptheta)$ is its conjugate prior \cite{theodoridis-ML}; thus, the model posterior PDF given the training data is
\begin{IEEEeqnarray}{rCl}
\prm(\uptheta | \Drm) & = & \frac{\Prm(\Drm | \uptheta) \prm(\uptheta)}{\Prm(\Drm)} \\
& = & \beta \left( \alpha + \bar{N}(\Drm) \right)^{-1} \prod_{y \in \Ycal} \prod_{x \in \Xcal} 
\uptheta(y,x)^{\alpha(y,x) + \bar{N}(y,x;\Drm) - 1} \nonumber \;, 
\end{IEEEeqnarray}
a Dirichlet distribution with parameter function $\alpha + \bar{N}(\Drm)$.

The concentration parameter increases proportionately with increasing volumes of training data; thus as $N \to \infty$, the posterior converges to $\prm(\uptheta | \Drm) \to \delta\big( \uptheta - \bar{N}(\Drm) / N \big)$. As more data is collected, the model can be more positively identified and used to formulate minimum risk decisions. Conversely, as $\alpha_0 \to \infty$, the prior model certainty is stronger and the posterior trends toward $\prm(\uptheta | \Drm) \to \delta( \uptheta - \alpha / \alpha_0)$, independent of the training data.

Figure \ref{fig:P_theta_D} shows the influence of the training data on the model distribution; after conditioning on the training data (via $\nbarrm$), the PDF concentration shifts away from the models favored by the prior knowledge and towards other models that better account for the observations.

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{P_theta_post.pdf}
\caption{Model $\uptheta$ PDF, prior and posterior}
\label{fig:P_theta_D}
\end{figure}


The joint PMF of $\yrm$ and $\xrm$ conditioned on the training data is expressed as \cite{murphy}
\begin{IEEEeqnarray}{rCl}
\Prm(\yrm,\xrm | \Drm) & = & \frac{\Erm_{\uptheta}\big[ \uptheta(\yrm,\xrm) \Prm(\Drm | \uptheta) \big]}{\Prm(\Drm)} \\
& = & \mu_{\uptheta | \Drm}(\yrm,\xrm) = \frac{\alpha(\yrm,\xrm) + \bar{N}(\yrm,\xrm;\Drm)}{\alpha_0 + N} \nonumber \\
& = & \left(\frac{\alpha_0}{\alpha_0 + N}\right) \frac{\alpha(\yrm,\xrm)}{\alpha_0} + \left(\frac{N}{\alpha_0 + N}\right) \frac{\bar{N}(\yrm,\xrm;\Drm)}{N} \nonumber \\
& = & \left(\frac{\alpha_0}{\alpha_0 + N}\right) \Prm(\yrm,\xrm) + \left(\frac{N}{\alpha_0 + N}\right) \frac{\bar{N}(\yrm,\xrm;\Drm)}{N} \nonumber \;.
\end{IEEEeqnarray}
This is a mixture distribution between the prior expectation $\Erm[\uptheta] = \alpha/\alpha_0$ and the empirical distribution $\bar{N}(\Drm)/N$. The more subjective the model prior (i.e. larger $\alpha_0$), the more the prior mean is favored; the more data, the more the empirical PMF is favored. The marginal distribution for $\xrm$ given $\Drm$ is
\begin{IEEEeqnarray}{rCl}
\Prm(\xrm | \Drm) & = & \frac{\alpha'(\xrm) + N'(\xrm;\Drm)}{\alpha_0 + N} \\
& = & \left(\frac{\alpha_0}{\alpha_0 + N}\right) \frac{\alpha'(\xrm)}{\alpha_0} + \left(\frac{N}{\alpha_0 + N}\right) \frac{N'(\xrm;\Drm)}{N} \nonumber \\
& = & \left(\frac{\alpha_0}{\alpha_0 + N}\right) \Prm(\xrm) + \left(\frac{N}{\alpha_0 + N}\right) \frac{N'(\xrm;\Drm)}{N} \nonumber \;.
\end{IEEEeqnarray}

Finally, the distribution of interest is generated via Bayes rule as
\begin{IEEEeqnarray}{rCl}
\Prm(\yrm | \xrm,\Drm) & = & \frac{\Prm(\yrm,\xrm | \Drm)}{\Prm(\xrm | \Drm)} = \frac{\alpha(\yrm,\xrm) + \bar{N}(\yrm,\xrm;\Drm)}{\alpha'(\xrm) + N'(\xrm;\Drm)} \\
& = & \left(\frac{\alpha'(\xrm)}{\alpha'(\xrm) + N'(\xrm;\Drm)}\right) \frac{\alpha(\yrm,\xrm)}{\alpha'(\xrm)} + \left(\frac{N'(\xrm;\Drm)}{\alpha'(\xrm) + N'(\xrm;\Drm)}\right) \frac{\bar{N}(\yrm,\xrm;\Drm)}{N'(\xrm;\Drm)} \nonumber \\
& = & \left(\frac{\alpha'(\xrm)}{\alpha'(\xrm) + N'(\xrm;\Drm)}\right) \Prm(\yrm | \xrm) + \left(\frac{N'(\xrm;\Drm)}{\alpha'(\xrm) + N'(\xrm;\Drm)}\right) \frac{\bar{N}(\yrm,\xrm;\Drm)}{N'(\xrm;\Drm)} \nonumber \;,
\end{IEEEeqnarray}
The last representation views the distribution as a convex combination of two conditional distributions. The first distribution $\Prm(\yrm | \xrm) = \alpha(\yrm,\xrm) / \alpha'(\xrm)$ is independent of the training data and based on the prior knowledge implied via the model PDF parameter; the second distribution is the ``conditional'' empirical PMF and depends on $\Drm$, not on $\alpha$. For both, only those values $\alpha$ and $\Drm$ corresponding to the observed value $\xrm$ influence the distribution. 

The weighting factors are dependent on these values as well. For $N'(\xrm;\Drm) = 0$ or as $\alpha_0 \to \infty$, the PMF trends toward the conditional distribution $\Prm(\yrm|\xrm)$, which only depends on the model parameter $\alpha$. As the number of training examples increases or as $\alpha_0 \to 0$, $\Prm(\yrm | \xrm,\Drm)$ trends towards the empirical conditional distribution. 









\section{Density Estimation Perspective}

It is informative to treat the distribution $\Prm(\yrm | \xrm,\Drm)$ as an estimate of the unknown conditional PMF $\Prm(\yrm | \xrm,\uptheta)$ and investigate the effects of subjective prior knowledge. For a given $\xrm$ and corresponding number of training samples $\nrm'(\xrm)$, the expected value of the estimate condtioned on the true model $\uptheta$ is
\begin{IEEEeqnarray}{L}
\Erm_{\nbarrm | \nrm',\uptheta}\big[ \Prm_{\yrm | \xrm,\nbarrm}(y | \xrm,\nbarrm) \big] \\ 
\quad = \left(\frac{\alpha'(\xrm)}{\alpha'(\xrm) + \nrm'(\xrm)}\right) \frac{\alpha(y,\xrm)}{\alpha'(\xrm)} + \left(\frac{\nrm'(\xrm)}{\alpha'(\xrm) + \nrm'(\xrm)}\right) \frac{\uptheta(y,\xrm)}{\uptheta'(\xrm)} \nonumber \;,
\end{IEEEeqnarray}
where the properties of a multinomial distribution conditioned on its aggregation have been used. The result is a convex combination of the conditional data-independent distribution $\alpha(\cdot,x) / \alpha'(x)$ and the true conditional distribution $\uptheta(\cdot,x) / \uptheta'(x)$. The convex coefficients are dependent on the ``marginal'' values $\alpha'$ and $\nrm'$; note that as the number of matching training samples $\nrm'(x)$ increases relative to $\alpha'(x)$, the estimate trends towards the true conditional PMF. 

To aid characterization of the estimator, define the random process $\Delta(y;\xrm,\nbarrm) \equiv \Prm_{\yrm | \xrm,\nbarrm}(y | \xrm,\nbarrm) - \Prm_{\yrm | \xrm,\uptheta}(y | \xrm,\uptheta)$. For a given $\xrm$ and corresponding number of training samples $\nrm'(\xrm)$, the bias of the conditional PMF estimate is
\begin{IEEEeqnarray}{rCl}
\mathrm{Bias}(y;\xrm,\nrm') & = & \Erm_{\nbarrm | \nrm',\uptheta}\big[ \Delta(y;\xrm,\nbarrm) \big] \\
& = & \frac{\alpha'(\xrm)}{\alpha'(\xrm) + \nrm'(\xrm)} \left( \frac{\alpha(y,\xrm)}{\alpha'(\xrm)} - \frac{\uptheta(y,\xrm)}{\uptheta'(\xrm)} \right) \nonumber 
\end{IEEEeqnarray}
and its covariance function is 
\begin{IEEEeqnarray}{L}
\mathrm{Var}(y,y';\xrm,\nrm') = \Crm_{\nbarrm | \nrm',\uptheta} \big[\Prm_{\yrm | \xrm,\nbarrm}(\cdot | \xrm,\nbarrm) \big](y,y') \\
\quad = \frac{\Sigma_{\nbarrm(\cdot,\xrm) | \nrm'(\xrm),\uptheta}(y,y')}{\big( \alpha'(\xrm) + \nrm'(\xrm) \big)^2} \nonumber \\
\quad = \frac{\nrm'(\xrm)}{\big( \alpha'(\xrm) + \nrm'(\xrm) \big)^2} \left( \frac{\uptheta(y,\xrm)}{\uptheta'(\xrm)} \delta[y,y'] - \frac{\uptheta(y,\xrm)}{\uptheta'(\xrm)} \frac{\uptheta(y',\xrm)}{\uptheta'(\xrm)} \right) \nonumber \;,
\end{IEEEeqnarray}
where the properties of multinomial random processes have been used. Note that the bias is proportionate to the difference between the true conditional model and the data-independent estimate. The scaling factor trends to zero as $\nrm'(x)/\alpha'(x) \to \infty$; as such, more subjective priors (large $\alpha'(x)$) will lead to PMF estimates that are prone to bias. Conversely, the variance of the PMF estimate decreases with increasing $\alpha'(x)$. 


Combining the estimator bias and variance, the squared difference between the estimate and the true conditional model is
\begin{IEEEeqnarray}{rCl}
\mathcal{E}(y,y' ; \xrm,\nrm') & = & \Erm_{\nbarrm | \nrm',\uptheta} \Big[ \Delta(y;\xrm,\nbarrm) \Delta(y';\xrm,\nbarrm) \Big] \\
& = & \mathrm{Bias}(y;\xrm,\nrm') \mathrm{Bias}(y';\xrm,\nrm') + \mathrm{Var}(y,y';\xrm,\nrm') \nonumber \;.
\end{IEEEeqnarray}
As $\nrm'(x) \to \infty$, this function trends to zero and thus the underlying model $\uptheta(\cdot,x) / \uptheta'(x)$ is determined precisely. A more practical case is estimation with a finite volume of training data. Specification of the Dirichlet model prior can be interpreted as providing a distribution estimate $\alpha(\cdot,x)/\alpha'(x)$ and a confidence level $\alpha'(x)$. Higher confidence reduces error due to the variance of the estimator, but increases the error due to bias between the true model and its estimate; low confidence renders the estimate unbiased, but maximizes the estimator variance. 



To exemplify how the model estimate $\Prm(\yrm | \xrm,\Drm)$ approximates $\Prm(\yrm | \xrm,\uptheta)$, consider a scenario with $|\Ycal| = 10$. The data-independent PMF $\alpha / \alpha_0$ and true model $\uptheta$ are shown in Figure \ref{fig:P_yx_error_N_0} - note the significant mismatch. 

Figures \ref{fig:P_yx_error_a0_0_1} and \ref{fig:P_yx_error_a0_10} show how the expected value and variance of the estimate (represented by the blue markers and error bars, respectively) change for different values of $\nrm'(x)$ and $\alpha'(x)$ . Each individual plot heading provides the error $\sqrt{\sum_{y \in \Ycal} \mathcal{E}(y,y ; \xrm,\nrm')}$ to assess the quality of the PMF estimate. Observe that for $\nrm'(x) = 1$, the high variance of the $\alpha'(x) = 0.1$ estimate (favoring the empirical PMF) renders it worse than the $\alpha_0 = 10$ estimate; in fact, the variance is so high that the error exceeds that of the data-independent estimate $\alpha(\cdot,x) / \alpha'(x)$ (Figure \ref{fig:P_yx_error_N_0}). Conversely, for $\nrm'(x) = 10$, the confidence of the $\alpha'(x) = 10$ estimate leads to high bias and the $\alpha'(x) = 0.1$ estimate is superior.


\begin{figure}
\centering
\includegraphics[width=1\linewidth]{P_yx_error_N_0.pdf}
\caption{Model $\uptheta$ estimate, no training data}
\label{fig:P_yx_error_N_0}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{P_yx_error_a0_0_1.pdf}
\caption{Model $\uptheta$ estimates, $\alpha_0 = 0.1$}
\label{fig:P_yx_error_a0_0_1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{P_yx_error_a0_10.pdf}
\caption{Model $\uptheta$ estimates, $\alpha_0 = 10$}
\label{fig:P_yx_error_a0_10}
\end{figure}


























\bibliographystyle{plain}
\bibliography{{../References/phd_bib}}

\end{document}


























