
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>User Guide &#8212; Statistical Learning  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="stats_learn" href="stats_learn.html" />
    <link rel="prev" title="Statistical Learning package documentation" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="index.html">
<p class="title">Statistical Learning</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="current reference internal nav-link" href="#">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="stats_learn.html">
  stats_learn
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#installation">
   Installation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quickstart">
   Quickstart
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="user-guide">
<h1>User Guide<a class="headerlink" href="#user-guide" title="Permalink to this headline">#</a></h1>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">#</a></h2>
<p>To use Statistical Learning, first install the local package using pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install &lt;path&gt;
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">&lt;path&gt;</span></code> should point to the top-level directory containing <code class="docutils literal notranslate"><span class="pre">setup.cfg</span></code>.</p>
</div>
<div class="section" id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h2>
<p>A basic example of model creation, learner definition, and performance assessment is shown below. The <code class="docutils literal notranslate"><span class="pre">model</span></code>
attribute defines a jointly Normal distribution where the expected value of <code class="docutils literal notranslate"><span class="pre">y</span></code> conditioned on <code class="docutils literal notranslate"><span class="pre">x</span></code> is
characterized by a polynomial function.</p>
<p>Two different predictors are instantiated. First, the <code class="docutils literal notranslate"><span class="pre">opt_predictor</span></code> uses knowledge of the <cite>model</cite> to
determine the optimal <code class="docutils literal notranslate"><span class="pre">predict</span></code> function. Second, a learning regressor is formulated using a Bayesian data
model <code class="docutils literal notranslate"><span class="pre">norm_model</span></code>; this object implements a Normal distribution <code class="docutils literal notranslate"><span class="pre">norm_model.prior</span></code> to characterize
uncertainty about the true model <code class="docutils literal notranslate"><span class="pre">weights</span></code>.</p>
<p>Training and testing data are randomly generated using the model <code class="docutils literal notranslate"><span class="pre">sample</span></code> method and each predictor is assessed
using its <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> method. Once the learning <code class="docutils literal notranslate"><span class="pre">norm_predictor</span></code> is <code class="docutils literal notranslate"><span class="pre">fit</span></code> to the data, its
squared-error loss is reduced.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stats_learn</span> <span class="kn">import</span> <span class="n">random</span><span class="p">,</span> <span class="n">bayes</span>
<span class="kn">from</span> <span class="nn">stats_learn.predictors</span> <span class="kn">import</span> <span class="n">ModelRegressor</span><span class="p">,</span> <span class="n">BayesRegressor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">NormalLinear</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Predictors</span>
<span class="n">opt_predictor</span> <span class="o">=</span> <span class="n">ModelRegressor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Optimal&#39;</span><span class="p">)</span>

<span class="n">norm_model</span> <span class="o">=</span> <span class="n">bayes</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">NormalLinear</span><span class="p">(</span><span class="n">prior_mean</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">prior_cov</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">norm_predictor</span> <span class="o">=</span> <span class="n">BayesRegressor</span><span class="p">(</span><span class="n">norm_model</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Normal&#39;</span><span class="p">)</span>

<span class="c1"># Results</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">12345</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">d_train</span><span class="p">,</span> <span class="n">d_test</span> <span class="o">=</span> <span class="n">d</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">d</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>

<span class="n">loss_min</span> <span class="o">=</span> <span class="n">opt_predictor</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">d_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum loss = </span><span class="si">{</span><span class="n">loss_min</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">loss_prior</span> <span class="o">=</span> <span class="n">norm_predictor</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">d_test</span><span class="p">)</span>  <span class="c1"># use the prior distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Untrained learner loss = </span><span class="si">{</span><span class="n">loss_prior</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">norm_predictor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d_train</span><span class="p">)</span>  <span class="c1"># fit the posterior distribution</span>
<span class="n">loss_fit</span> <span class="o">=</span> <span class="n">norm_predictor</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">d_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trained learner loss = </span><span class="si">{</span><span class="n">loss_fit</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Minimum loss = 0.549
Prior learner loss = 3.413
Trained learner loss = 0.951
</pre></div>
</div>
<p>The code below can be executed after the previous snippet. The <code class="code docutils literal notranslate"><span class="pre">data_assess</span></code> function provides replication of the
functionality above, including a loss table and a graphic showing how the <code class="code docutils literal notranslate"><span class="pre">predict</span></code> functions fit the training
data. The <code class="code docutils literal notranslate"><span class="pre">model_assess</span></code> function performs Monte Carlo approximation of the expected loss by repeatedly
generating and evaluating on new datasets, enabling statistically meaningful evaluation. Observe that it can be used
for both visualization of both the prediction statistics and of the average loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stats_learn</span> <span class="kn">import</span> <span class="n">results</span>

<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="n">opt_predictor</span><span class="p">,</span> <span class="n">norm_predictor</span><span class="p">]</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;prior_cov&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}]</span>

<span class="c1"># Sample regressor realizations</span>
<span class="n">results</span><span class="o">.</span><span class="n">data_assess</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">d_train</span><span class="p">,</span> <span class="n">d_test</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_fit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Prediction mean/variance</span>
<span class="n">results</span><span class="o">.</span><span class="n">model_assess</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_mc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">stats</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">plot_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">print_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Squared-Error vs. training data volume</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">model_assess</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_mc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<img alt="_images/ex_basic_fit.png" src="_images/ex_basic_fit.png" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>|                                 |    10 |
|---------------------------------|-------|
| Optimal                         | 0.549 |
| Normal, $\Sigma_\theta = 0.010$ | 3.171 |
| Normal, $\Sigma_\theta = 0.100$ | 2.034 |
| Normal, $\Sigma_\theta = 1.000$ | 0.951 |
</pre></div>
</div>
<img alt="_images/ex_basic_stats.png" src="_images/ex_basic_stats.png" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>|                                 |    10 |
|---------------------------------|-------|
| Optimal                         | 1.005 |
| Normal, $\Sigma_\theta = 0.010$ | 2.689 |
| Normal, $\Sigma_\theta = 0.100$ | 1.629 |
| Normal, $\Sigma_\theta = 1.000$ | 1.205 |
</pre></div>
</div>
<img alt="_images/ex_basic_loss.png" src="_images/ex_basic_loss.png" />
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Statistical Learning package documentation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="stats_learn.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">stats_learn</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Paul Rademacher.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>